{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup notebook\n",
    "from pathlib import Path\n",
    "\n",
    "# import necessary package\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data\n",
    "comp_dir = Path('../input/store-sales-time-series-forecasting')\n",
    "\n",
    "store_sales = pd.read_csv(comp_dir / 'train.csv',\n",
    "    usecols=['store_nbr', 'family', 'date', 'sales', 'onpromotion'],\n",
    "    dtype={\n",
    "        'store_nbr': 'category',\n",
    "        'family': 'category',\n",
    "        'sales': 'float32',\n",
    "        'onpromotion': 'uint32',},\n",
    "    parse_dates=['date'],\n",
    "    infer_datetime_format=True,)\n",
    "\n",
    "test = pd.read_csv(comp_dir / 'test.csv',\n",
    "    dtype={\n",
    "        'store_nbr': 'category',\n",
    "        'family': 'category',\n",
    "        'onpromotion': 'uint32',},\n",
    "    parse_dates=['date'],\n",
    "    infer_datetime_format=True,)\n",
    "\n",
    "oil = pd.read_csv(comp_dir / 'oil.csv',\n",
    "    parse_dates=['date'],\n",
    "    infer_datetime_format=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that define all the EDA we need \n",
    "def EDA(df):\n",
    "    print(\"\\n_____ HEAD OF THE DATA _____\")\n",
    "    print(df.head())\n",
    "    print(\"\\n_____ INFO _____\")\n",
    "    print(df.info())\n",
    "    print(\"\\n_____ Describe _____\")\n",
    "    print(df.describe())\n",
    "    print(\"\\n_____ Columns _____\")\n",
    "    print(df.columns)\n",
    "    print(\"\\n_____ Data Types _____\")\n",
    "    print(df.dtypes)\n",
    "    print(\"\\n_____ Missing Values _____\")\n",
    "    print(df.isnull().sum())\n",
    "    print(\"\\n_____ NULL values _____\")\n",
    "    print(df.isna().sum())\n",
    "    print(\"\\n_____ Shape Of Data _____\")\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"__________ Sales Data __________\")\n",
    "EDA(store_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"__________ Test data __________\")\n",
    "EDA(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"__________ Oil Price __________\")\n",
    "EDA(oil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing date\n",
    "oil = oil.set_index(\"date\").asfreq(freq = \"D\")\n",
    "\n",
    "# fill the NaN value by interpolation\n",
    "oil[\"dcoilwtico\"] = oil[\"dcoilwtico\"].interpolate(limit_direction=\"both\")\n",
    "\n",
    "oil.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_sales = store_sales.merge(oil, on=\"date\")\n",
    "test = test.merge(oil, on=\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, futureArr=None, targetCol=None, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('%s(t-%d)' % (j, i)) for j in df.columns]\n",
    "        \n",
    "    # forecast sequence (t, t+1, ... t+n)    \n",
    "    if futureArr != None:\n",
    "        for i in range(0, n_out):\n",
    "            for futureCol in futureArr:\n",
    "                cols.append(df.shift(-i)[futureCol])\n",
    "                if i == 0:\n",
    "                    names += [('%s(t)' % (futureCol))]\n",
    "                else:\n",
    "                    names += [('%s(t+%d)' % (futureCol, i))]\n",
    "    \n",
    "    for i in range(0, n_out):\n",
    "        if targetCol == None:\n",
    "            cols.append(df.shift(-i))\n",
    "            if i == 0:\n",
    "                names += [('%s(t)' % (j)) for j in df.columns]\n",
    "            else:\n",
    "                names += [('%s(t+%d)' % (j, i)) for j in df.columns]\n",
    "        else:\n",
    "            cols.append(df.shift(-i)[targetCol])\n",
    "            if i == 0:\n",
    "                names += [('%s(t)' % (targetCol))]\n",
    "            else:\n",
    "                names += [('%s(t+%d)' % (targetCol, i))]\n",
    "            \n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_nbr_types = store_sales[\"store_nbr\"].unique()\n",
    "\n",
    "family_types = store_sales[\"family\"].unique()\n",
    "\n",
    "for store_nbr_type in store_nbr_types:\n",
    "    for family_type in family_types:\n",
    "        train_data = store_sales[(store_sales[\"store_nbr\"] == store_nbr_type) & (store_sales[\"family\"] == family_type)]\n",
    "        \n",
    "        train_data = train_data.reset_index()\n",
    "        train_data = train_data.drop(columns = [\"index\", \"date\", \"store_nbr\", \"family\"])\n",
    "              \n",
    "        test_data = test[(test[\"store_nbr\"] == store_nbr_type) & (test[\"family\"] == family_type)]\n",
    "        test_data = test_data.drop(columns = [\"date\", \"store_nbr\", \"family\"])\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat train and test data\n",
    "total_data = pd.concat([train_data, test_data]).drop(columns=[\"id\"])\n",
    "\n",
    "total_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "feature_name = total_data.columns\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler(feature_range = (0,1))\n",
    "\n",
    "total_data = scaler.fit_transform(total_data)\n",
    "\n",
    "total_data = pd.DataFrame(total_data, columns=feature_name)\n",
    "\n",
    "total_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "futureArr = [\"onpromotion\", \"dcoilwtico\"]\n",
    "\n",
    "series_to_supervised(total_data, 5, 2, futureArr=futureArr, targetCol=\"sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_days = 50\n",
    "predict_days = 16\n",
    "futureArr = [\"onpromotion\", \"dcoilwtico\"]\n",
    "targetCol = \"sales\"\n",
    "\n",
    "train = series_to_supervised(total_data, past_days, predict_days, futureArr, targetCol)\n",
    "\n",
    "split_ratio = 0.8\n",
    "\n",
    "split_number = np.floor(len(train.index) * split_ratio)\n",
    "split_number = np.int(split_number)\n",
    "\n",
    "values = train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and validation sets\n",
    "train = values[:split_number, :]\n",
    "val = values[split_number:, :]\n",
    "\n",
    "# split into input and outputs\n",
    "train_x, train_y = train[:, :-predict_days], train[:, -predict_days:]\n",
    "val_x, val_y = val[:, :-predict_days], val[:, -predict_days:]\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_x = train_x.reshape((train_x.shape[0], 1, train_x.shape[1]))\n",
    "val_x = val_x.reshape((val_x.shape[0], 1, val_x.shape[1]))\n",
    "\n",
    "prediction_data = series_to_supervised(total_data, past_days, predict_days, futureArr, targetCol, dropnan=False).values[-17:-16, :-predict_days]\n",
    "prediction_data = prediction_data.reshape((prediction_data.shape[0], 1, prediction_data.shape[1]))\n",
    "\n",
    "print(train_x.shape, train_y.shape, val_x.shape, val_y.shape, prediction_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.LSTM(units=128, return_sequences=True, input_shape=(train_x.shape[1], train_x.shape[2])),\n",
    "    keras.layers.LSTM(units=128, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(predict_days))\n",
    "])\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\", metrics=[\"mse\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping =  keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "model_result = model.fit(train_x, train_y, epochs=100, batch_size=32, validation_data=(val_x, val_y), verbose=2, shuffle=False, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot history\n",
    "plt.figure(figsize=(30, 10))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(model_result.history[\"loss\"], label=\"training\")\n",
    "plt.plot(model_result.history[\"val_loss\"], label=\"validation\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(model_result.history[\"mse\"], label=\"training\")\n",
    "plt.plot(model_result.history[\"val_mse\"], label=\"validation\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(prediction_data)\n",
    "\n",
    "prediction = np.squeeze(prediction) / scaler.scale_[0]\n",
    "\n",
    "test_data[\"sales\"] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_nbr_types = store_sales[\"store_nbr\"].unique()\n",
    "\n",
    "family_types = store_sales[\"family\"].unique()\n",
    "\n",
    "counter = 0\n",
    "for store_nbr_type in store_nbr_types:\n",
    "    for family_type in family_types:\n",
    "        counter = counter + 1\n",
    "        train_data = store_sales[(store_sales[\"store_nbr\"] == store_nbr_type) & (store_sales[\"family\"] == family_type)]\n",
    "        train_data = train_data.reset_index()\n",
    "        train_data = train_data.drop(columns = [\"index\", \"date\", \"store_nbr\", \"family\"])      \n",
    "        test_data = test[(test[\"store_nbr\"] == store_nbr_type) & (test[\"family\"] == family_type)]\n",
    "        test_data = test_data.drop(columns = [\"date\", \"store_nbr\", \"family\"])\n",
    "        \n",
    "        # concat train and test data\n",
    "        total_data = pd.concat([train_data, test_data]).drop(columns=[\"id\"])\n",
    "        \n",
    "        # Normalization\n",
    "        feature_name = total_data.columns\n",
    "\n",
    "        scaler = preprocessing.MinMaxScaler(feature_range = (0,1))\n",
    "\n",
    "        total_data = scaler.fit_transform(total_data)\n",
    "\n",
    "        total_data = pd.DataFrame(total_data, columns=feature_name)\n",
    "        past_days = 50\n",
    "        predict_days = 16\n",
    "        futureArr = [\"onpromotion\", \"dcoilwtico\"]\n",
    "        targetCol = \"sales\"\n",
    "        train = series_to_supervised(total_data, past_days, predict_days, futureArr, targetCol)\n",
    "        split_ratio = 0.8\n",
    "        split_number = np.floor(len(train.index) * split_ratio)\n",
    "        split_number = np.int(split_number)\n",
    "        values = train.values\n",
    "\n",
    "\n",
    "        # split into train and validation sets\n",
    "        train = values[:split_number, :]\n",
    "        val = values[split_number:, :]\n",
    "\n",
    "        # split into input and outputs\n",
    "        train_x, train_y = train[:, :-predict_days], train[:, -predict_days:]\n",
    "        val_x, val_y = val[:, :-predict_days], val[:, -predict_days:]\n",
    "        # reshape input to be 3D [samples, timesteps, features]\n",
    "        train_x = train_x.reshape((train_x.shape[0], 1, train_x.shape[1]))\n",
    "        val_x = val_x.reshape((val_x.shape[0], 1, val_x.shape[1]))\n",
    "\n",
    "        prediction_data = series_to_supervised(total_data, past_days, predict_days, futureArr, targetCol, dropnan=False).values[-17:-16, :-predict_days]\n",
    "        prediction_data = prediction_data.reshape((prediction_data.shape[0], 1, prediction_data.shape[1]))\n",
    "        \n",
    "        # Model\n",
    "        model = keras.models.Sequential([\n",
    "            keras.layers.LSTM(units=128, return_sequences=True, input_shape=(train_x.shape[1], train_x.shape[2])),\n",
    "            keras.layers.LSTM(units=128, return_sequences=True),\n",
    "            keras.layers.TimeDistributed(keras.layers.Dense(predict_days))\n",
    "        ])\n",
    "\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "        model.compile(optimizer=\"adam\", loss=\"mean_squared_error\", metrics=[\"mse\"])\n",
    "        \n",
    "        # Train\n",
    "        early_stopping =  keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "        model_result = model.fit(train_x, train_y, epochs=25, batch_size=32, validation_data=(val_x, val_y), verbose=0, shuffle=False, callbacks=[early_stopping])\n",
    "        \n",
    "        # Inference        \n",
    "        prediction = model.predict(prediction_data)\n",
    "        prediction = np.squeeze(prediction) / scaler.scale_[0]\n",
    "        test_data[\"sales\"] = prediction\n",
    "        if counter == 1:\n",
    "            submit_data = test_data\n",
    "        else:\n",
    "            submit_data = pd.concat([submit_data, test_data])\n",
    "        if counter % 50 == 0:\n",
    "            print(counter)\n",
    "                \n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_data = submit_data.drop(columns = [\"onpromotion\", \"dcoilwtico\"])\n",
    "submit_data = submit_data.sort_values(by=[\"id\"])\n",
    "submit_data = submit_data.reset_index(drop=True)\n",
    "submit_data.loc[submit_data.sales < 0.001, \"sales\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_data.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
